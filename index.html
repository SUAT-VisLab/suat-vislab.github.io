---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: main_page
title: VisLab@SUAT
permalink: /
---

  <!-- Header -->
  <header class="masthead">
    <div class="container d-flex h-100 align-items-center">
      <div class="mx-auto text-center">
        <h3 class="text-white-50 mx-auto mt-2 mb-5">Welcome to Vision-Lab@SUAT</h3>
      </div>
    </div>
  </header>

  <section  class="projects-section bg-light">
    <div class="container">

      <!-- About  Row -->
      <div id="About" class="row align-items-center no-gutters mb-4 mb-lg-5 section-container">

        <div class="col-xl-12 col-lg-12">
          <div class="featured-text text-lg-left">
            <h4>About</h4>

            <p>
            We are the Vision Laboratory at Shenzhen University of Advanced Technology (VisLab-SUAT). Our research focuses on Computer Vision, Artificial Intelligence, Video Analysis, 
            Multimodal Foundation Models, Image Processing, and Machine Vision.
  
            <p>
            We are a dynamic and interdisciplinary team committed to advancing the frontiers of visual intelligence. By combining theoretical innovation with practical application, 
            we aim to build intelligent systems that can perceive, reason, and act in complex real-world environments.
            <p>
             At VisLab, we emphasize academic excellence, open collaboration, and real-world impact. Our work spans from algorithm design to system deployment, 
              with applications in robotics, smart cities, autonomous systems, and beyond.
          </div>
        </div>
      </div>

      <!-- Faculty -->
      <div id="Faculty" class="row align-items-center no-gutters mb-4 mb-lg-5 section-container">

        <div class="col-xl-12 col-lg-12">
          <div class="featured-text text-lg-left">
            <h4>Faculty</h4>
            
            {% include faculty_cards.html faculty=site.data.faculty %}

          </div>
        </div>
      </div>
      
      
      <!-- Students -->
      <div id="Students" class="row align-items-center no-gutters mb-4 mb-lg-5 section-container">

        <div class="col-xl-12 col-lg-12">
          <div class="featured-text text-lg-left">
            <h4>Students</h4>

            <h5>PhD students</h5>

            {% include student_cards.html students=site.data.students.phd %}

            <h5>MS students</h5>

            {% include student_cards.html students=site.data.students.ms %}
            
            <h5>BS students</h5>

            {% include student_cards.html students=site.data.students.bs %}

            <h5>Research Assistans</h5>

            {% include student_cards.html students=site.data.students.ra %}

          </div>
        </div>
      </div>

      <!-- Alumni -->
      <div id="Alumni" class="row align-items-center no-gutters mb-4 mb-lg-5 section-container">

        <div class="col-xl-12 col-lg-12">
          <div class="featured-text text-lg-left">
            <h4>Alumni</h4>
             Coming Soon...
<!--             <h5>PhD Alumni</h5>

            {% include alumni_cards.html alumni=site.data.alumni.phd prefix="Dr." %}

            <h5>MS Alumni</h5>

            {% include alumni_cards.html alumni=site.data.alumni.ms %}
 -->
          </div>
        </div>
      </div>

      <!-- Research -->
     <!-- Research Publications -->
    <div id="Research" class="row align-items-center no-gutters mb-4 mb-lg-5 section-container">
      <div class="col-xl-12 col-lg-12">
        <div class="featured-text text-lg-left">
          <h4>Selected Publications</h4>
    
          <ul class="list-group list-group-flush">
    
            <!-- 2025 -->
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <a href="https://arxiv.org/abs/2508.01253" target="_blank">
                <strong>ODOV: Towards Open-Domain Open-Vocabulary Object Detection</strong>
              </a><br>
              <span class="text-muted">arXiv preprint, 2025</span>
              <span class="badge badge-warning badge-pill">Under Review</span>
            </li>
    
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <strong>From Indoor to Outdoor: Unsupervised Domain Adaptive Gait Recognition</strong><br>
              <span class="text-muted">Pattern Recognition, 2025</span>
              <span class="badge badge-success badge-pill">CCF B</span>
            </li>
    
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <strong>Synthetic-To-Real Video Person Re-ID</strong><br>
              <span class="text-muted">IEEE Transactions on Information Forensics and Security (TIFS), 2025</span>
              <span class="badge badge-primary badge-pill">CCF A</span>
            </li>
    
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <strong>A Large-Scale Combinatorial Benchmark for Sign Language Recognition</strong><br>
              <span class="text-muted">Pattern Recognition, 2025</span>
              <span class="badge badge-success badge-pill">CCF B</span>
            </li>
    
            <!-- 2024 -->
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <a href="https://doi.org/10.1007/s11263-023-01857-z" target="_blank">
                <strong>Benchmarking the Complementary-View Multi-human Association and Tracking</strong>
              </a><br>
              <span class="text-muted">International Journal of Computer Vision (IJCV), 2024</span>
              <span class="badge badge-primary badge-pill">CCF A</span>
            </li>
    
            <!-- 2023 -->
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <strong>Relating view directions of complementary-view mobile cameras via the human shadow</strong><br>
              <span class="text-muted">International Journal of Computer Vision (IJCV), 2023</span>
              <span class="badge badge-primary badge-pill">CCF A</span>
            </li>
    
            <!-- 2022 -->
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <strong>Panoramic Human Activity Recognition</strong><br>
              <span class="text-muted">European Conference on Computer Vision (ECCV), 2022</span>
              <span class="badge badge-primary badge-pill">CCF A</span>
            </li>
    
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <strong>Connecting the Complementary-View Videos: Joint Camera Identification and Subject Association</strong><br>
              <span class="text-muted">CVPR (IEEE/CVF Conference on Computer Vision and Pattern Recognition), 2022</span>
              <span class="badge badge-primary badge-pill">CCF A</span>
            </li>
    
            <!-- 2021 -->
            <li class="list-group-item d-flex justify-content-between align-items-center">
              <strong>Multiple Human Association and Tracking from Egocentric and Complementary Top Views</strong><br>
              <span class="text-muted">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021</span>
              <span class="badge badge-primary badge-pill">CCF A</span>
            </li>
    
          </ul>
        </div>
      </div>
    </div>

    </div>
  </section>
